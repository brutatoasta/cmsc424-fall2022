{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fb22ba",
   "metadata": {},
   "source": [
    "You can use this notebook to develop your answers. Make sure to look at intermediate results using `take()` for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa321e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "## Load data into RDDs\n",
    "usersRDD = sc.textFile(\"datafiles/se_users.json\").map(json.loads)\n",
    "postsRDD = sc.textFile(\"datafiles/se_posts.json\").map(json.loads)\n",
    "playRDD = sc.textFile(\"datafiles/play.txt\")\n",
    "logsRDD = sc.textFile(\"datafiles/NASA_logs_sample.txt\")\n",
    "amazonInputRDD = sc.textFile(\"datafiles/amazon-ratings.txt\")\n",
    "nobelRDD = sc.textFile(\"datafiles/prize.json\").map(json.loads)\n",
    "amazonBipartiteRDD = amazonInputRDD.map(lambda x: x.split(\" \")).map(lambda x: (x[0], x[1])).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00474973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 2, 'posttypeid': 1, 'title': 'How can a group track database schema changes?', 'acceptedanswerid': 4, 'parentid': None, 'creationdate': '2011-01-03', 'score': 68, 'viewcount': 11533, 'owneruserid': 7, 'lasteditoruserid': 97, 'tags': '<mysql><version-control><schema>'}\n",
      "{'id': 3, 'posttypeid': 1, 'title': 'What is an effective way of labeling columns in a database?', 'acceptedanswerid': None, 'parentid': None, 'creationdate': '2011-01-03', 'score': 30, 'viewcount': 1302, 'owneruserid': 17, 'lasteditoruserid': 97, 'tags': '<database-design><erd>'}\n",
      "{'id': 4, 'posttypeid': 2, 'title': None, 'acceptedanswerid': None, 'parentid': 2, 'creationdate': '2011-01-03', 'score': 46, 'viewcount': None, 'owneruserid': 18, 'lasteditoruserid': 1396, 'tags': None}\n"
     ]
    }
   ],
   "source": [
    "for t in postsRDD.take(3): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68285f23",
   "metadata": {},
   "source": [
    "Task 1 (0.25): Use filter to find all posts where tags are not null (None in python) and that are tagged 'postgresql-9.4', and then a map so that the output RDD has tuples of the form: (ID, Title, Tags). Note that postsRDD contains dictionaries -- see the contents by running postsRDD.take(10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06b78ffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def task1(postsRDD):\n",
    "    res = postsRDD.filter(\n",
    "        lambda x: x.get(\"tags\")!= None).filter(\n",
    "        lambda x: \"postgresql-9.4\" in x.get(\"tags\")).map(\n",
    "        lambda x: (x.get(\"id\"), x.get(\"title\"), x.get(\"tags\"))\n",
    "    )\n",
    "    return res \n",
    "a = task1(postsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2972012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89480, 'PostgreSQL timezone setting', '<postgresql><postgresql-9.4>')\n",
      "(89555, 'Retrieving latest record using DISTINCT ON is slow', '<postgresql><index><performance><postgresql-9.4><query-performance>')\n",
      "(89746, 'Use result of aggregate in same select?', '<postgresql><postgresql-9.4>')\n",
      "(89971, 'PostgreSql JSONB SELECT against multiple values', '<postgresql><json><postgresql-9.4>')\n",
      "(90002, 'PostgreSQL operator uses index but underlying function does not', '<postgresql><index-tuning><json><postgresql-9.4><operator>')\n",
      "(90360, 'Rely on .pgpass in CREATE USER MAPPING', '<postgresql><postgresql-9.4><foreign-data>')\n",
      "(95214, 'Working with Materialized View', '<postgresql><materialized-view><postgresql-9.4><pgbouncer>')\n",
      "(95758, 'PostgreSQL update and delete property from JSONB column', '<postgresql><postgresql-9.4>')\n",
      "(95778, 'Clarification on UNION ALL of JSONB_EACH result', '<postgresql><postgresql-9.4>')\n",
      "(45870, 'How to do incremental backup every hour in Postgres?', '<postgresql><backup><windows><postgresql-9.4>')\n"
     ]
    }
   ],
   "source": [
    "for t in a.take(10): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f1db81",
   "metadata": {},
   "source": [
    "Task 2 (0.25): Use flatMap on the postsRDD to create an RDD (ID, Tag), listing all the tags for each post as a separate tuple. If a post has no tags, it should not appear in the output RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ebd9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task2FlatMapper(dic):\n",
    "    res = []\n",
    "    tags = dic.get(\"tags\").replace(\"<\", \"\").replace(\">\", \" \").split(\" \")\n",
    "    tags.pop()\n",
    "    for i in tags:\n",
    "        res.append( (dic.get(\"id\"), i)\n",
    "        )\n",
    "    return res\n",
    "    \n",
    "\n",
    "def task2(postsRDD):\n",
    "    return postsRDD.filter(\n",
    "        lambda x: x.get(\"tags\")!= None).flatMap(\n",
    "        task2FlatMapper\n",
    "    )\n",
    "a = task2(postsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ece0a8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 'mysql')\n",
      "(2, 'version-control')\n",
      "(2, 'schema')\n",
      "(3, 'database-design')\n",
      "(3, 'erd')\n",
      "(5, 'nosql')\n",
      "(5, 'rdbms')\n",
      "(5, 'database-recommendation')\n",
      "(6, 'postgresql')\n",
      "(6, 'replication')\n"
     ]
    }
   ],
   "source": [
    "for t in a.take(10): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96595bc2",
   "metadata": {},
   "source": [
    "Task 3 (0.25): The goal here is to find the 5 lexicographically smallest tags for each year, for the posts from that year. So the outputRDD should be contain tuples of the form: ('2001', ['tag1', 'tag2', ..., 'tag5']), with 'tag1' < 'tag2' and 'tag5' being smaller (lexicographically) than any other tag for a post from that year. All the five (or fewer for some of the years) tags should be distinct. Use a map followed by reduceByKey for doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e57d90f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task3MapA(dic):\n",
    "    # get the year and tags for each row in postsRDD\n",
    "    year = dic[\"creationdate\"][:4]\n",
    "    tags = dic.get(\"tags\").replace(\"<\", \"\").replace(\">\", \" \").split(\" \")\n",
    "    tags.pop()\n",
    "    res = (year, set(tags)) # change to set for set union in reduceByKey\n",
    "    return res\n",
    "def task3MapB(tu):\n",
    "    # return to list for sorting, limit to top 5\n",
    "    x = tu[1]\n",
    "    x = list(x)\n",
    "    x.sort()\n",
    "    return (tu[0], x[:5])\n",
    "\n",
    "def task3(postsRDD):\n",
    "    return postsRDD.filter(\n",
    "        lambda x: x.get(\"tags\")!= None).map(\n",
    "            task3MapA).reduceByKey( # set union to remove duplicates\n",
    "                lambda v1, v2: v1 | v2).map(task3MapB)\n",
    "a = task3(postsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72693f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2011', ['access-control', 'active-directory', 'activity-monitor', 'ado.net', 'aggregate'])\n",
      "('2014', ['access-control', 'acid', 'active-directory', 'activity-monitor', 'address'])\n",
      "('2015', ['access-control', 'active-directory', 'ado.net', 'aggregate', 'alter-database'])\n",
      "('2010', ['data-warehouse', 'database-design', 'dbcc', 'export', 'import'])\n",
      "('2012', ['access-control', 'active-directory', 'activity-monitor', 'address', 'ado.net'])\n",
      "('2013', ['access-control', 'acid', 'active-directory', 'activity-monitor', 'address'])\n",
      "('2009', ['career', 'ssas'])\n"
     ]
    }
   ],
   "source": [
    "for t in a.take(100): print(t)\n",
    "# print(len(a.collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7070dc7",
   "metadata": {},
   "source": [
    "Task 4 (0.25): Use join to join the usersRDD and postsRDD on users.id = owneruserid. The output should be a tuple of the form: (userid, displayname, postid, posttitle). You will need to do several maps to do this. Make sure you look at the structure of the objects with the RDD after the join; it will need to postprocessed using a map to get to the desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d3da795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def userTup(dic):\n",
    "    res = (dic[\"id\"] , dic[\"displayname\"])\n",
    "    return res\n",
    "\n",
    "def postsTup(dic):\n",
    "    res = (dic[\"owneruserid\"], (dic[\"id\"], dic[\"title\"]))\n",
    "    return res\n",
    "\n",
    "def combTup(tu):\n",
    "    a = tu[0]\n",
    "    b= tu[1][0]\n",
    "    c = tu[1][1][0]\n",
    "    d = tu[1][1][1]\n",
    "    return (a, b, c, d)\n",
    "\n",
    "def task4(usersRDD, postsRDD):\n",
    "    rdd1 = usersRDD.map(userTup)\n",
    "    rdd2 = postsRDD.map(postsTup)\n",
    "    rdd3 = rdd1.join(rdd2)\n",
    "    return rdd3.map(combTup)\n",
    "\n",
    "c = task4(usersRDD, postsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "319bfb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "(-1, 'Community')\n",
      "(2, 'Geoff Dalgas')\n",
      "(3, 'balpha')\n",
      "b\n",
      "(7, (2, 'How can a group track database schema changes?'))\n",
      "(17, (3, 'What is an effective way of labeling columns in a database?'))\n",
      "(18, (4, None))\n",
      "c\n",
      "(8, 'ilhan', 2107, 'How to get a users friends names?')\n",
      "(8, 'ilhan', 6255, 'Should I record ID numbers in a table where I record who look whom profile page')\n",
      "(8, 'ilhan', 42729, 'Merging two Access tables into one')\n"
     ]
    }
   ],
   "source": [
    "for t in c.take(3): print(t)\n",
    "# print(len(a.collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bd5e5b",
   "metadata": {},
   "source": [
    "Task 5 (0.25): Using the postsRDD, create an RDD where the key is a 2-tuple (title-word, tag), where the former is a word in a title, and the latter is a tag. The value associated with the key should be the number of posts in which the title-word is in the title, and the tag is in the tags for that post. This will require a couple of flatMaps (to separate tags into individual tag values as well as to separate the title into its words) and an aggregateByKey to count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520d6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find title word tag first using previous questions\n",
    "# find num posts separately \n",
    "# combine\n",
    "\n",
    "def task5(postsRDD):\n",
    "    # (title-word, tag) : num posts where title-word in title\n",
    "    \n",
    "    return dummyrdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5ae1ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task5MapA(dic):\n",
    "    res = []\n",
    "    # get the title word and tags for each row in postsRDD\n",
    "    postid = dic.get(\"id\")\n",
    "    words = dic.get(\"title\").split(\" \")\n",
    "    tags = dic.get(\"tags\").replace(\"<\", \"\").replace(\">\", \" \").split(\" \")\n",
    "    tags.pop()\n",
    "    for word in words:\n",
    "        for tag in tags:\n",
    "            res.append( (postid, word, tag) )\n",
    "#     res = set(res)\n",
    "#     res = list(res)\n",
    "    return res\n",
    "def task5MapB(dic):\n",
    "    res = []\n",
    "    # get the title word and tags for each row in postsRDD\n",
    "    postid = dic.get(\"id\")\n",
    "    words = dic.get(\"title\").split(\" \")\n",
    "    for word in words:\n",
    "        res.append( (postid, word) )\n",
    "    return res\n",
    "\n",
    "def task5(postsRDD):\n",
    "    rdd1 = postsRDD.filter(\n",
    "        lambda x: x.get(\"tags\")!= None).filter(\n",
    "        lambda x: x.get(\"title\")!= None).flatMap(\n",
    "            task5MapA)\n",
    "    # count num posts where title-word in title\n",
    "    rdd2 = postsRDD.filter(\n",
    "        lambda x: x.get(\"tags\")!= None).filter(\n",
    "        lambda x: x.get(\"title\")!= None).flatMap(\n",
    "            task5MapB)\n",
    "    return rdd2\n",
    "#     tup = rdd1.map(lambda x : (x, 0))\n",
    "#     res = tup.aggregateByKey(1, lambda x,y:x+y , lambda x,y: x+y)\n",
    "#     return res\n",
    "c = task5(postsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9426b65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 'How')\n",
      "(2, 'can')\n",
      "(2, 'a')\n",
      "(2, 'group')\n",
      "(2, 'track')\n",
      "(2, 'database')\n",
      "(2, 'schema')\n",
      "(2, 'changes?')\n",
      "(3, 'What')\n",
      "(3, 'is')\n",
      "(3, 'an')\n",
      "(3, 'effective')\n",
      "(3, 'way')\n",
      "(3, 'of')\n",
      "(3, 'labeling')\n",
      "(3, 'columns')\n",
      "(3, 'in')\n",
      "(3, 'a')\n",
      "(3, 'database?')\n",
      "(5, 'What')\n",
      "(5, 'are')\n",
      "(5, 'the')\n",
      "(5, 'differences')\n",
      "(5, 'between')\n",
      "(5, 'NoSQL')\n",
      "(5, 'and')\n",
      "(5, 'a')\n",
      "(5, 'traditional')\n",
      "(5, 'RDBMS?')\n",
      "(6, 'What')\n",
      "(6, 'is')\n",
      "(6, 'the')\n",
      "(6, 'difference')\n",
      "(6, 'between')\n",
      "(6, 'PostgreSQL')\n",
      "(6, '9.0')\n",
      "(6, 'Replication')\n",
      "(6, 'and')\n",
      "(6, 'Slony-I?')\n",
      "(14, 'When')\n",
      "(14, 'is')\n",
      "(14, 'the')\n",
      "(14, 'right')\n",
      "(14, 'time')\n",
      "(14, 'to')\n",
      "(14, 'use')\n",
      "(14, 'MariaDB')\n",
      "(14, 'instead')\n",
      "(14, 'of')\n",
      "(14, 'MySQL,')\n",
      "(14, 'and')\n",
      "(14, 'Why?')\n",
      "(20, 'How')\n",
      "(20, 'can')\n",
      "(20, 'I')\n",
      "(20, 'optimize')\n",
      "(20, 'a')\n",
      "(20, 'mysqldump')\n",
      "(20, 'of')\n",
      "(20, 'a')\n",
      "(20, 'large')\n",
      "(20, 'database?')\n",
      "(21, 'Is')\n",
      "(21, 'it')\n",
      "(21, 'possible')\n",
      "(21, 'to')\n",
      "(21, 'use')\n",
      "(21, 'SQLite')\n",
      "(21, 'as')\n",
      "(21, 'a')\n",
      "(21, 'client-server')\n",
      "(21, 'database?')\n",
      "(29, 'Where')\n",
      "(29, 'are')\n",
      "(29, 'some')\n",
      "(29, 'useful')\n",
      "(29, 'SQL')\n",
      "(29, 'puzzles')\n",
      "(29, 'to')\n",
      "(29, 'teach')\n",
      "(29, 'SQL')\n",
      "(29, 'in')\n",
      "(29, 'a')\n",
      "(29, 'workplace?')\n",
      "(30, 'Is')\n",
      "(30, 'there')\n",
      "(30, 'a')\n",
      "(30, 'good')\n",
      "(30, 'way')\n",
      "(30, 'to')\n",
      "(30, 'run')\n",
      "(30, 'a')\n",
      "(30, 'trigger')\n",
      "(30, 'for')\n",
      "(30, 'each')\n",
      "(30, 'record')\n",
      "(30, 'in')\n",
      "(30, 'a')\n",
      "(30, 'postgres')\n",
      "(30, 'table?')\n"
     ]
    }
   ],
   "source": [
    "for t in c.take(100): print(t)\n",
    "# print(len(a.collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d592f",
   "metadata": {},
   "source": [
    "Task 6 (0.25): Write the function that takes as input the amazonInputRDD (which is an RDD of lines) and maps each line to a tuple while removing the initial descriptor, i.e., the first line \"user1 product1 5.0\" gets mapped to a tuple (1, 1, 5.0). This just requires a single map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd780226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task6mapper(line):\n",
    "    words = line.replace(\"user\", \"\").replace(\"product\", \"\").split(\" \")\n",
    "    return (int(words[0]), int(words[1]), float(words[2]))\n",
    "   \n",
    "def task6(amazonInputRDD):\n",
    "    return amazonInputRDD.map(task6mapper)\n",
    "a = task6(amazonInputRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5826f04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 5.0)\n",
      "(1, 2, 1.0)\n",
      "(1, 3, 5.0)\n",
      "(1, 4, 1.0)\n",
      "(1, 5, 1.0)\n",
      "(1, 6, 5.0)\n",
      "(1, 7, 4.0)\n",
      "(1, 8, 5.0)\n",
      "(1, 9, 5.0)\n",
      "(1, 10, 1.0)\n"
     ]
    }
   ],
   "source": [
    "for t in a.take(10): print(t)\n",
    "# print(len(a.collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d0cc03",
   "metadata": {},
   "source": [
    "Task 7 (0.25): Complete the function that takes as input the amazonInputRDD and computes the average rating for each user across all the products they reviewed. The output should be an RDD of 2-tuples of the form (user1, 2.87) (not the correct answer). You can either use aggregateByKey or a reduceByKey followed by a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "dd6bbd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task7mapA(line):\n",
    "    words = line.split()\n",
    "    # return (words[0], (1, float(words[2])) )\n",
    "    return (words[0],  float(words[2]))\n",
    "\n",
    "def task7(amazonInputRDD):\n",
    "    aTuple = (0,0)\n",
    "    cleaned = amazonInputRDD.map(task7mapA)\n",
    "    rdd1 = cleaned.aggregateByKey(aTuple, lambda a,b: (a[0] + b,    a[1] + 1),\n",
    "                                       lambda a,b: (a[0] + b[0], a[1] + b[1]))\n",
    "    # get average\n",
    "    return rdd1.mapValues(lambda v: v[0]/v[1])\n",
    "\n",
    "# First lambda expression for Within-Partition Reduction Step::\n",
    "#    a: is a TUPLE that holds: (runningSum, runningCount).\n",
    "#    b: is a SCALAR that holds the next Value\n",
    "\n",
    "#    Second lambda expression for Cross-Partition Reduction Step::\n",
    "#    a: is a TUPLE that holds: (runningSum, runningCount).\n",
    "#    b: is a TUPLE that holds: (nextPartitionsSum, nextPartitionsCount).\n",
    "a = task7(amazonInputRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "eccd7aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('user1', 4.08)\n",
      "('user2', 3.5238095238095237)\n"
     ]
    }
   ],
   "source": [
    "for t in a.take(2): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc2f510",
   "metadata": {},
   "source": [
    "Task 8 (0.25): Complete the function that takes as input the amazonInputRDD and computes the mode rating for each product across all users (i.e., the rating that was most common for that product). If there are ties, pick the higher rating. Easiest way to do this would be a groupByKey followed by a map to compute the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2f35186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task8mapA(line):\n",
    "    words = line.split()\n",
    "    \n",
    "    return ((words[1],  float(words[2])) ,0)\n",
    "\n",
    "# count the number of unique tuples (product 181, 4.0) \n",
    "def task8(amazonInputRDD):\n",
    "    cleaned = amazonInputRDD.map(task8mapA)\n",
    "    rdd1 = cleaned.groupByKey()\\\n",
    "    .mapValues(lambda vals: len(vals))\\\n",
    "    .sortByKey()\n",
    "    # rdd1 ((name, rating), count)\n",
    "    # rdd2, mode (name, count) \n",
    "    # rdd3 ((name, count), rating)\n",
    "    # rdd4 ((name, count), 0)\n",
    "    \n",
    "    # get mode\n",
    "    rdd2 = rdd1.map(lambda x: (x[0][0], x[1])) # contains the count of every key\n",
    "    mode = rdd2.reduceByKey(max)\n",
    "    rdd3 = rdd1.map(lambda x: ((x[0][0], x[1]), x[0][1]))\n",
    "    # rdd3 = rdd1.map(lambda x: (x[0][0], x[1]), x[0][1])\n",
    "    rdd4 = mode.map(lambda x: (x, 0))\n",
    "    res = rdd3.join(rdd4) # join on same count\n",
    "    res = res.map(lambda x: (x[0][0], x[1][0]) ).sortByKey()\n",
    "    return res\n",
    "\n",
    "a = task8(amazonInputRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4bd4f612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('product0', 5.0)\n",
      "('product1', 5.0)\n",
      "('product10', 5.0)\n",
      "('product100', 5.0)\n",
      "('product101', 5.0)\n",
      "('product102', 5.0)\n",
      "('product103', 5.0)\n",
      "('product104', 5.0)\n",
      "('product105', 5.0)\n",
      "('product106', 5.0)\n",
      "('product107', 5.0)\n",
      "('product108', 5.0)\n",
      "('product109', 5.0)\n",
      "('product11', 5.0)\n",
      "('product110', 4.0)\n",
      "('product110', 5.0)\n",
      "('product111', 5.0)\n",
      "('product112', 5.0)\n",
      "('product113', 5.0)\n",
      "('product114', 5.0)\n",
      "('product115', 5.0)\n",
      "('product116', 5.0)\n",
      "('product117', 5.0)\n",
      "('product118', 5.0)\n",
      "('product119', 5.0)\n",
      "('product12', 5.0)\n",
      "('product120', 4.0)\n",
      "('product121', 5.0)\n",
      "('product122', 5.0)\n",
      "('product123', 5.0)\n",
      "('product124', 5.0)\n",
      "('product125', 5.0)\n",
      "('product126', 5.0)\n",
      "('product127', 5.0)\n",
      "('product128', 5.0)\n",
      "('product129', 5.0)\n",
      "('product13', 5.0)\n",
      "('product130', 5.0)\n",
      "('product131', 5.0)\n",
      "('product132', 5.0)\n",
      "('product133', 5.0)\n",
      "('product134', 5.0)\n",
      "('product135', 5.0)\n",
      "('product136', 5.0)\n",
      "('product137', 5.0)\n",
      "('product138', 5.0)\n",
      "('product139', 5.0)\n",
      "('product14', 5.0)\n",
      "('product140', 5.0)\n",
      "('product141', 5.0)\n",
      "('product142', 5.0)\n",
      "('product143', 5.0)\n",
      "('product144', 5.0)\n",
      "('product145', 5.0)\n",
      "('product146', 5.0)\n",
      "('product147', 5.0)\n",
      "('product148', 5.0)\n",
      "('product149', 5.0)\n",
      "('product15', 5.0)\n",
      "('product150', 5.0)\n",
      "('product151', 5.0)\n",
      "('product152', 5.0)\n",
      "('product153', 5.0)\n",
      "('product154', 5.0)\n",
      "('product155', 5.0)\n",
      "('product156', 5.0)\n",
      "('product157', 4.0)\n",
      "('product158', 5.0)\n",
      "('product159', 5.0)\n",
      "('product16', 5.0)\n",
      "('product160', 5.0)\n",
      "('product161', 5.0)\n",
      "('product162', 5.0)\n",
      "('product163', 5.0)\n",
      "('product164', 5.0)\n",
      "('product165', 5.0)\n",
      "('product166', 5.0)\n",
      "('product167', 5.0)\n",
      "('product168', 5.0)\n",
      "('product169', 5.0)\n",
      "('product17', 5.0)\n",
      "('product170', 5.0)\n",
      "('product171', 5.0)\n",
      "('product172', 5.0)\n",
      "('product173', 5.0)\n",
      "('product174', 5.0)\n",
      "('product175', 5.0)\n",
      "('product176', 5.0)\n",
      "('product177', 4.0)\n",
      "('product177', 5.0)\n",
      "('product178', 5.0)\n",
      "('product179', 5.0)\n",
      "('product18', 5.0)\n",
      "('product180', 5.0)\n",
      "('product181', 5.0)\n",
      "('product182', 5.0)\n",
      "('product183', 5.0)\n",
      "('product184', 5.0)\n",
      "('product185', 5.0)\n",
      "('product186', 5.0)\n",
      "('product187', 5.0)\n",
      "('product188', 5.0)\n",
      "('product189', 5.0)\n",
      "('product19', 5.0)\n",
      "('product190', 5.0)\n",
      "('product191', 5.0)\n",
      "('product192', 5.0)\n",
      "('product193', 5.0)\n",
      "('product194', 5.0)\n",
      "('product195', 5.0)\n",
      "('product196', 5.0)\n",
      "('product197', 5.0)\n",
      "('product198', 5.0)\n",
      "('product199', 5.0)\n",
      "('product2', 5.0)\n",
      "('product20', 4.0)\n",
      "('product200', 5.0)\n",
      "('product201', 5.0)\n",
      "('product202', 5.0)\n",
      "('product203', 5.0)\n",
      "('product204', 4.0)\n",
      "('product205', 5.0)\n",
      "('product206', 5.0)\n",
      "('product207', 5.0)\n",
      "('product208', 5.0)\n",
      "('product209', 4.0)\n",
      "('product209', 5.0)\n",
      "('product21', 5.0)\n",
      "('product210', 5.0)\n",
      "('product211', 5.0)\n",
      "('product212', 5.0)\n",
      "('product213', 5.0)\n",
      "('product214', 5.0)\n",
      "('product215', 5.0)\n",
      "('product216', 5.0)\n",
      "('product217', 5.0)\n",
      "('product218', 4.0)\n",
      "('product219', 5.0)\n",
      "('product22', 5.0)\n",
      "('product220', 4.0)\n",
      "('product221', 4.0)\n",
      "('product222', 5.0)\n",
      "('product223', 4.0)\n",
      "('product223', 5.0)\n",
      "('product224', 5.0)\n",
      "('product225', 5.0)\n",
      "('product226', 5.0)\n",
      "('product227', 5.0)\n",
      "('product228', 5.0)\n",
      "('product229', 5.0)\n",
      "('product23', 5.0)\n",
      "('product230', 5.0)\n",
      "('product231', 5.0)\n",
      "('product232', 5.0)\n",
      "('product233', 5.0)\n",
      "('product234', 5.0)\n",
      "('product235', 5.0)\n",
      "('product236', 5.0)\n",
      "('product237', 5.0)\n",
      "('product238', 5.0)\n",
      "('product239', 4.0)\n",
      "('product24', 5.0)\n",
      "('product240', 5.0)\n",
      "('product241', 5.0)\n",
      "('product242', 5.0)\n",
      "('product243', 5.0)\n",
      "('product244', 5.0)\n",
      "('product245', 5.0)\n",
      "('product246', 5.0)\n",
      "('product247', 5.0)\n",
      "('product248', 4.0)\n",
      "('product249', 5.0)\n",
      "('product25', 5.0)\n",
      "('product250', 5.0)\n",
      "('product251', 5.0)\n",
      "('product252', 5.0)\n",
      "('product253', 5.0)\n",
      "('product254', 5.0)\n",
      "('product255', 5.0)\n",
      "('product256', 5.0)\n",
      "('product257', 5.0)\n",
      "('product258', 5.0)\n",
      "('product259', 5.0)\n",
      "('product26', 5.0)\n",
      "('product260', 5.0)\n",
      "('product261', 5.0)\n",
      "('product262', 5.0)\n",
      "('product263', 5.0)\n",
      "('product264', 5.0)\n",
      "('product265', 5.0)\n",
      "('product266', 5.0)\n",
      "('product267', 5.0)\n",
      "('product268', 5.0)\n",
      "('product269', 4.0)\n",
      "('product27', 5.0)\n",
      "('product270', 5.0)\n",
      "('product271', 5.0)\n",
      "('product272', 5.0)\n",
      "('product273', 5.0)\n",
      "('product274', 4.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for t in a.take(200): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9866b05",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb83fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "01b0da322a7df2b881bf69dce4c75684d5ac75b853286a49a713693279c2c23c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
