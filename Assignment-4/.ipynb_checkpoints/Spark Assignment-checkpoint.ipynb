{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f2fb3e",
   "metadata": {},
   "source": [
    "You can use this notebook to develop your answers. Make sure to look at intermediate results using `take()` for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b48020bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "## Load data into RDDs\n",
    "usersRDD = sc.textFile(\"datafiles/se_users.json\").map(json.loads)\n",
    "postsRDD = sc.textFile(\"datafiles/se_posts.json\").map(json.loads)\n",
    "playRDD = sc.textFile(\"datafiles/play.txt\")\n",
    "logsRDD = sc.textFile(\"datafiles/NASA_logs_sample.txt\")\n",
    "amazonInputRDD = sc.textFile(\"datafiles/amazon-ratings.txt\")\n",
    "nobelRDD = sc.textFile(\"datafiles/prize.json\").map(json.loads)\n",
    "amazonBipartiteRDD = amazonInputRDD.map(lambda x: x.split(\" \")).map(lambda x: (x[0], x[1])).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e24f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 2, 'posttypeid': 1, 'title': 'How can a group track database schema changes?', 'acceptedanswerid': 4, 'parentid': None, 'creationdate': '2011-01-03', 'score': 68, 'viewcount': 11533, 'owneruserid': 7, 'lasteditoruserid': 97, 'tags': '<mysql><version-control><schema>'}\n",
      "{'id': 3, 'posttypeid': 1, 'title': 'What is an effective way of labeling columns in a database?', 'acceptedanswerid': None, 'parentid': None, 'creationdate': '2011-01-03', 'score': 30, 'viewcount': 1302, 'owneruserid': 17, 'lasteditoruserid': 97, 'tags': '<database-design><erd>'}\n",
      "{'id': 4, 'posttypeid': 2, 'title': None, 'acceptedanswerid': None, 'parentid': 2, 'creationdate': '2011-01-03', 'score': 46, 'viewcount': None, 'owneruserid': 18, 'lasteditoruserid': 1396, 'tags': None}\n"
     ]
    }
   ],
   "source": [
    "for t in postsRDD.take(3): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e72eebb",
   "metadata": {},
   "source": [
    "Task 1 (0.25): Use filter to find all posts where tags are not null (None in python) and that are tagged 'postgresql-9.4', and then a map so that the output RDD has tuples of the form: (ID, Title, Tags). Note that postsRDD contains dictionaries -- see the contents by running postsRDD.take(10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f5a56f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def task1(postsRDD):\n",
    "    res = postsRDD.filter(\n",
    "        lambda x: x.get(\"tags\")!= None).filter(\n",
    "        lambda x: \"postgresql-9.4\" in x.get(\"tags\")).map(\n",
    "        lambda x: (x.get(\"id\"), x.get(\"title\"), x.get(\"tags\"))\n",
    "    )\n",
    "    return res \n",
    "a = task1(postsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "951620be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89480, 'PostgreSQL timezone setting', '<postgresql><postgresql-9.4>')\n",
      "(89555, 'Retrieving latest record using DISTINCT ON is slow', '<postgresql><index><performance><postgresql-9.4><query-performance>')\n",
      "(89746, 'Use result of aggregate in same select?', '<postgresql><postgresql-9.4>')\n",
      "(89971, 'PostgreSql JSONB SELECT against multiple values', '<postgresql><json><postgresql-9.4>')\n",
      "(90002, 'PostgreSQL operator uses index but underlying function does not', '<postgresql><index-tuning><json><postgresql-9.4><operator>')\n",
      "(90360, 'Rely on .pgpass in CREATE USER MAPPING', '<postgresql><postgresql-9.4><foreign-data>')\n",
      "(95214, 'Working with Materialized View', '<postgresql><materialized-view><postgresql-9.4><pgbouncer>')\n",
      "(95758, 'PostgreSQL update and delete property from JSONB column', '<postgresql><postgresql-9.4>')\n",
      "(95778, 'Clarification on UNION ALL of JSONB_EACH result', '<postgresql><postgresql-9.4>')\n",
      "(45870, 'How to do incremental backup every hour in Postgres?', '<postgresql><backup><windows><postgresql-9.4>')\n"
     ]
    }
   ],
   "source": [
    "for t in a.take(10): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e737f7db",
   "metadata": {},
   "source": [
    "Task 2 (0.25): Use flatMap on the postsRDD to create an RDD (ID, Tag), listing all the tags for each post as a separate tuple. If a post has no tags, it should not appear in the output RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58f07fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task2FlatMapper(dic):\n",
    "    res = []\n",
    "    tags = dic.get(\"tags\").replace(\"<\", \"\").replace(\">\", \" \").split(\" \")\n",
    "    tags.pop()\n",
    "    for i in tags:\n",
    "        res.append( (dic.get(\"id\"), i)\n",
    "        )\n",
    "    return res\n",
    "    \n",
    "\n",
    "def task2(postsRDD):\n",
    "    return postsRDD.filter(\n",
    "        lambda x: x.get(\"tags\")!= None).flatMap(\n",
    "        task2FlatMapper\n",
    "    )\n",
    "a = task2(postsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d47dc0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 'mysql')\n",
      "(2, 'version-control')\n",
      "(2, 'schema')\n",
      "(3, 'database-design')\n",
      "(3, 'erd')\n",
      "(5, 'nosql')\n",
      "(5, 'rdbms')\n",
      "(5, 'database-recommendation')\n",
      "(6, 'postgresql')\n",
      "(6, 'replication')\n"
     ]
    }
   ],
   "source": [
    "for t in a.take(10): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9dba16",
   "metadata": {},
   "source": [
    "Task 3 (0.25): The goal here is to find the 5 lexicographically smallest tags for each year, for the posts from that year. So the outputRDD should be contain tuples of the form: ('2001', ['tag1', 'tag2', ..., 'tag5']), with 'tag1' < 'tag2' and 'tag5' being smaller (lexicographically) than any other tag for a post from that year. All the five (or fewer for some of the years) tags should be distinct. Use a map followed by reduceByKey for doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d25379b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task3MapA(dic):\n",
    "    # get the year and tags for each row in postsRDD\n",
    "    year = dic[\"creationdate\"][:4]\n",
    "    tags = dic.get(\"tags\").replace(\"<\", \"\").replace(\">\", \" \").split(\" \")\n",
    "    tags.pop()\n",
    "    res = (year, set(tags)) # change to set for set union in reduceByKey\n",
    "    return res\n",
    "def task3MapB(tu):\n",
    "    # return to list for sorting, limit to top 5\n",
    "    x = tu[1]\n",
    "    x = list(x)\n",
    "    x.sort()\n",
    "    return (tu[0], x[:5])\n",
    "\n",
    "def task3(postsRDD):\n",
    "    return postsRDD.filter(\n",
    "        lambda x: x.get(\"tags\")!= None).map(\n",
    "            task3MapA).reduceByKey( # set union to remove duplicates\n",
    "                lambda v1, v2: v1 | v2).map(task3MapB)\n",
    "a = task3(postsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b611d3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2011', ['access-control', 'active-directory', 'activity-monitor', 'ado.net', 'aggregate'])\n",
      "('2014', ['access-control', 'acid', 'active-directory', 'activity-monitor', 'address'])\n",
      "('2015', ['access-control', 'active-directory', 'ado.net', 'aggregate', 'alter-database'])\n",
      "('2010', ['data-warehouse', 'database-design', 'dbcc', 'export', 'import'])\n",
      "('2012', ['access-control', 'active-directory', 'activity-monitor', 'address', 'ado.net'])\n",
      "('2013', ['access-control', 'acid', 'active-directory', 'activity-monitor', 'address'])\n",
      "('2009', ['career', 'ssas'])\n"
     ]
    }
   ],
   "source": [
    "for t in a.take(100): print(t)\n",
    "# print(len(a.collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea763ad",
   "metadata": {},
   "source": [
    "Task 4 (0.25): Use join to join the usersRDD and postsRDD on users.id = owneruserid. The output should be a tuple of the form: (userid, displayname, postid, posttitle). You will need to do several maps to do this. Make sure you look at the structure of the objects with the RDD after the join; it will need to postprocessed using a map to get to the desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a87cb485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def userTup(dic):\n",
    "    res = (dic[\"id\"] , dic[\"displayname\"])\n",
    "    return res\n",
    "\n",
    "def postsTup(dic):\n",
    "    res = (dic[\"owneruserid\"], (dic[\"id\"], dic[\"title\"]))\n",
    "    return res\n",
    "\n",
    "def combTup(tu):\n",
    "    a = tu[0]\n",
    "    b= tu[1][0]\n",
    "    c = tu[1][1][0]\n",
    "    d = tu[1][1][1]\n",
    "    return (a, b, c, d)\n",
    "\n",
    "def task4(usersRDD, postsRDD):\n",
    "    rdd1 = usersRDD.map(userTup)\n",
    "    rdd2 = postsRDD.map(postsTup)\n",
    "    rdd3 = rdd1.join(rdd2)\n",
    "    return rdd3.map(combTup)\n",
    "\n",
    "c = task4(usersRDD, postsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42aa2a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 'ilhan', 2107, 'How to get a users friends names?')\n",
      "(8, 'ilhan', 6255, 'Should I record ID numbers in a table where I record who look whom profile page')\n",
      "(8, 'ilhan', 42729, 'Merging two Access tables into one')\n"
     ]
    }
   ],
   "source": [
    "for t in c.take(3): print(t)\n",
    "# print(len(a.collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7054942",
   "metadata": {},
   "source": [
    "Task 5 (0.25): Using the postsRDD, create an RDD where the key is a 2-tuple (title-word, tag), where the former is a word in a title, and the latter is a tag. The value associated with the key should be the number of posts in which the title-word is in the title, and the tag is in the tags for that post. This will require a couple of flatMaps (to separate tags into individual tag values as well as to separate the title into its words) and an aggregateByKey to count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e71a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find title word tag first using previous questions\n",
    "# find num posts separately \n",
    "# combine\n",
    "\n",
    "def task5MapA(dic):\n",
    "    res = []\n",
    "    # get the title word and tags for each row in postsRDD\n",
    "    postid = dic.get(\"id\")\n",
    "    words = dic.get(\"title\").split(\" \")\n",
    "    tags = dic.get(\"tags\").replace(\"<\", \"\").replace(\">\", \" \").split(\" \")\n",
    "    tags.pop()\n",
    "    for word in words:\n",
    "        for tag in tags:\n",
    "            res.append( (postid, word, tag) )\n",
    "#     res = set(res)\n",
    "#     res = list(res)\n",
    "    return res\n",
    "def task5MapB(dic):\n",
    "    res = []\n",
    "    # get the title word and tags for each row in postsRDD\n",
    "    postid = dic.get(\"id\")\n",
    "    words = dic.get(\"title\").split(\" \")\n",
    "    for word in words:\n",
    "        res.append( (postid, word) )\n",
    "    return res\n",
    "\n",
    "def task5(postsRDD):\n",
    "    rdd1 = postsRDD.filter(\n",
    "        lambda x: x.get(\"tags\")!= None).filter(\n",
    "        lambda x: x.get(\"title\")!= None).flatMap(\n",
    "            task5MapA)\n",
    "    # count num posts where title-word in title\n",
    "    rdd2 = postsRDD.filter(\n",
    "        lambda x: x.get(\"tags\")!= None).filter(\n",
    "        lambda x: x.get(\"title\")!= None).flatMap(\n",
    "            task5MapB)\n",
    "    return rdd1\n",
    "#     tup = rdd1.map(lambda x : (x, 0))\n",
    "#     res = tup.aggregateByKey(1, lambda x,y:x+y , lambda x,y: x+y)\n",
    "#     return res\n",
    "c = task5(postsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec172be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 'How', 'mysql')\n",
      "(2, 'How', 'version-control')\n",
      "(2, 'How', 'schema')\n",
      "(2, 'can', 'mysql')\n",
      "(2, 'can', 'version-control')\n",
      "(2, 'can', 'schema')\n",
      "(2, 'a', 'mysql')\n",
      "(2, 'a', 'version-control')\n",
      "(2, 'a', 'schema')\n",
      "(2, 'group', 'mysql')\n",
      "(2, 'group', 'version-control')\n",
      "(2, 'group', 'schema')\n",
      "(2, 'track', 'mysql')\n",
      "(2, 'track', 'version-control')\n",
      "(2, 'track', 'schema')\n",
      "(2, 'database', 'mysql')\n",
      "(2, 'database', 'version-control')\n",
      "(2, 'database', 'schema')\n",
      "(2, 'schema', 'mysql')\n",
      "(2, 'schema', 'version-control')\n",
      "(2, 'schema', 'schema')\n",
      "(2, 'changes?', 'mysql')\n",
      "(2, 'changes?', 'version-control')\n",
      "(2, 'changes?', 'schema')\n",
      "(3, 'What', 'database-design')\n",
      "(3, 'What', 'erd')\n",
      "(3, 'is', 'database-design')\n",
      "(3, 'is', 'erd')\n",
      "(3, 'an', 'database-design')\n",
      "(3, 'an', 'erd')\n",
      "(3, 'effective', 'database-design')\n",
      "(3, 'effective', 'erd')\n",
      "(3, 'way', 'database-design')\n",
      "(3, 'way', 'erd')\n",
      "(3, 'of', 'database-design')\n",
      "(3, 'of', 'erd')\n",
      "(3, 'labeling', 'database-design')\n",
      "(3, 'labeling', 'erd')\n",
      "(3, 'columns', 'database-design')\n",
      "(3, 'columns', 'erd')\n",
      "(3, 'in', 'database-design')\n",
      "(3, 'in', 'erd')\n",
      "(3, 'a', 'database-design')\n",
      "(3, 'a', 'erd')\n",
      "(3, 'database?', 'database-design')\n",
      "(3, 'database?', 'erd')\n",
      "(5, 'What', 'nosql')\n",
      "(5, 'What', 'rdbms')\n",
      "(5, 'What', 'database-recommendation')\n",
      "(5, 'are', 'nosql')\n",
      "(5, 'are', 'rdbms')\n",
      "(5, 'are', 'database-recommendation')\n",
      "(5, 'the', 'nosql')\n",
      "(5, 'the', 'rdbms')\n",
      "(5, 'the', 'database-recommendation')\n",
      "(5, 'differences', 'nosql')\n",
      "(5, 'differences', 'rdbms')\n",
      "(5, 'differences', 'database-recommendation')\n",
      "(5, 'between', 'nosql')\n",
      "(5, 'between', 'rdbms')\n",
      "(5, 'between', 'database-recommendation')\n",
      "(5, 'NoSQL', 'nosql')\n",
      "(5, 'NoSQL', 'rdbms')\n",
      "(5, 'NoSQL', 'database-recommendation')\n",
      "(5, 'and', 'nosql')\n",
      "(5, 'and', 'rdbms')\n",
      "(5, 'and', 'database-recommendation')\n",
      "(5, 'a', 'nosql')\n",
      "(5, 'a', 'rdbms')\n",
      "(5, 'a', 'database-recommendation')\n",
      "(5, 'traditional', 'nosql')\n",
      "(5, 'traditional', 'rdbms')\n",
      "(5, 'traditional', 'database-recommendation')\n",
      "(5, 'RDBMS?', 'nosql')\n",
      "(5, 'RDBMS?', 'rdbms')\n",
      "(5, 'RDBMS?', 'database-recommendation')\n",
      "(6, 'What', 'postgresql')\n",
      "(6, 'What', 'replication')\n",
      "(6, 'is', 'postgresql')\n",
      "(6, 'is', 'replication')\n",
      "(6, 'the', 'postgresql')\n",
      "(6, 'the', 'replication')\n",
      "(6, 'difference', 'postgresql')\n",
      "(6, 'difference', 'replication')\n",
      "(6, 'between', 'postgresql')\n",
      "(6, 'between', 'replication')\n",
      "(6, 'PostgreSQL', 'postgresql')\n",
      "(6, 'PostgreSQL', 'replication')\n",
      "(6, '9.0', 'postgresql')\n",
      "(6, '9.0', 'replication')\n",
      "(6, 'Replication', 'postgresql')\n",
      "(6, 'Replication', 'replication')\n",
      "(6, 'and', 'postgresql')\n",
      "(6, 'and', 'replication')\n",
      "(6, 'Slony-I?', 'postgresql')\n",
      "(6, 'Slony-I?', 'replication')\n",
      "(14, 'When', 'mysql')\n",
      "(14, 'When', 'mariadb')\n",
      "(14, 'When', 'database-recommendation')\n",
      "(14, 'is', 'mysql')\n"
     ]
    }
   ],
   "source": [
    "for t in c.take(100): print(t)\n",
    "# print(len(a.collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce693e",
   "metadata": {},
   "source": [
    "Task 6 (0.25): Write the function that takes as input the amazonInputRDD (which is an RDD of lines) and maps each line to a tuple while removing the initial descriptor, i.e., the first line \"user1 product1 5.0\" gets mapped to a tuple (1, 1, 5.0). This just requires a single map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a058efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task6mapper(line):\n",
    "    words = line.replace(\"user\", \"\").replace(\"product\", \"\").split(\" \")\n",
    "    return (int(words[0]), int(words[1]), float(words[2]))\n",
    "   \n",
    "def task6(amazonInputRDD):\n",
    "    return amazonInputRDD.map(task6mapper)\n",
    "a = task6(amazonInputRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cb30183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 5.0)\n",
      "(1, 2, 1.0)\n",
      "(1, 3, 5.0)\n",
      "(1, 4, 1.0)\n",
      "(1, 5, 1.0)\n",
      "(1, 6, 5.0)\n",
      "(1, 7, 4.0)\n",
      "(1, 8, 5.0)\n",
      "(1, 9, 5.0)\n",
      "(1, 10, 1.0)\n"
     ]
    }
   ],
   "source": [
    "for t in a.take(10): print(t)\n",
    "# print(len(a.collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e99af6b",
   "metadata": {},
   "source": [
    "Task 7 (0.25): Complete the function that takes as input the amazonInputRDD and computes the average rating for each user across all the products they reviewed. The output should be an RDD of 2-tuples of the form (user1, 2.87) (not the correct answer). You can either use aggregateByKey or a reduceByKey followed by a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82dca481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task7mapA(line):\n",
    "    words = line.split()\n",
    "    # return (words[0], (1, float(words[2])) )\n",
    "    return (words[0],  float(words[2]))\n",
    "\n",
    "def task7(amazonInputRDD):\n",
    "    aTuple = (0,0)\n",
    "    cleaned = amazonInputRDD.map(task7mapA)\n",
    "    rdd1 = cleaned.aggregateByKey(aTuple, lambda a,b: (a[0] + b,    a[1] + 1),\n",
    "                                       lambda a,b: (a[0] + b[0], a[1] + b[1]))\n",
    "    # get average\n",
    "    return rdd1.mapValues(lambda v: v[0]/v[1])\n",
    "\n",
    "# First lambda expression for Within-Partition Reduction Step::\n",
    "#    a: is a TUPLE that holds: (runningSum, runningCount).\n",
    "#    b: is a SCALAR that holds the next Value\n",
    "\n",
    "#    Second lambda expression for Cross-Partition Reduction Step::\n",
    "#    a: is a TUPLE that holds: (runningSum, runningCount).\n",
    "#    b: is a TUPLE that holds: (nextPartitionsSum, nextPartitionsCount).\n",
    "a = task7(amazonInputRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9da1ea92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('user1', 4.08)\n",
      "('user2', 3.5238095238095237)\n"
     ]
    }
   ],
   "source": [
    "for t in a.take(2): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf2f366",
   "metadata": {},
   "source": [
    "Task 8 (0.25): Complete the function that takes as input the amazonInputRDD and computes the mode rating for each product across all users (i.e., the rating that was most common for that product). If there are ties, pick the higher rating. Easiest way to do this would be a groupByKey followed by a map to compute the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd7f8ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task8mapA(line):\n",
    "    words = line.split() \n",
    "    return ((words[1],  float(words[2])) ,0)\n",
    "\n",
    "# count the number of unique tuples (product 181, 4.0) \n",
    "def task8(amazonInputRDD):\n",
    "    cleaned = amazonInputRDD.map(task8mapA)\n",
    "    rdd1 = cleaned.groupByKey()\\\n",
    "    .mapValues(lambda vals: len(vals))\\\n",
    "    .sortByKey()\n",
    "    # rdd1 ((name, rating), count)\n",
    "    # rdd2, mode (name, count) \n",
    "    # rdd3 ((name, count), rating)\n",
    "    # rdd4 ((name, count), 0)\n",
    "    \n",
    "    # get mode\n",
    "    rdd2 = rdd1.map(lambda x: (x[0][0], x[1])) # contains the count of every key\n",
    "    mode = rdd2.reduceByKey(max)\n",
    "    rdd3 = rdd1.map(lambda x: ((x[0][0], x[1]), x[0][1]))\n",
    "    # rdd3 = rdd1.map(lambda x: (x[0][0], x[1]), x[0][1])\n",
    "    rdd4 = mode.map(lambda x: (x, 0))\n",
    "    res = rdd3.join(rdd4) # join on same count\n",
    "    res = res.map(lambda x: (x[0][0], x[1][0]) ).sortByKey()\n",
    "    return res\n",
    "\n",
    "a = task8(amazonInputRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "798b869c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('product0', 5.0)\n",
      "('product1', 5.0)\n",
      "('product10', 5.0)\n",
      "('product100', 5.0)\n",
      "('product101', 5.0)\n",
      "('product102', 5.0)\n",
      "('product103', 5.0)\n",
      "('product104', 5.0)\n",
      "('product105', 5.0)\n",
      "('product106', 5.0)\n",
      "('product107', 5.0)\n",
      "('product108', 5.0)\n",
      "('product109', 5.0)\n",
      "('product11', 5.0)\n",
      "('product110', 4.0)\n",
      "('product110', 5.0)\n",
      "('product111', 5.0)\n",
      "('product112', 5.0)\n",
      "('product113', 5.0)\n",
      "('product114', 5.0)\n"
     ]
    }
   ],
   "source": [
    "for t in a.take(20): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8caf84",
   "metadata": {},
   "source": [
    "Task 9 (0.25): For logsRDD, write a function that computes the number of log requests for each year. So the output should be an RDD with records of the form (1995, 2952) (not the correct answer). This can be done through a map to extract the years, followed by a group by aggregate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcbb1df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task9(logsRDD):\n",
    "    def getYear(line):\n",
    "        words = line.split()\n",
    "        year = words[3][8:12]\n",
    "        return (year, 0)\n",
    "    rdd1 = logsRDD.map(getYear).groupByKey()\\\n",
    "    .mapValues(lambda vals: len(vals))\\\n",
    "    .sortByKey()\n",
    "    return rdd1\n",
    "\n",
    "a = task9(logsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd741c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1995', 10000)\n"
     ]
    }
   ],
   "source": [
    "for t in a.take(200): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fee606",
   "metadata": {},
   "source": [
    "Task 10 (0.25): Write just the flatmap function task10_flatmap that operates on playRDD -- for each line, it outputs the individual words sanitized to remove any non-alphanumerical characters. So for the 3rd line, it would output a list: [Enter, LEONATO, HERO, and, BEATRICE, with, a, Messenger]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27acb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task10_flatmap(line):\n",
    "    filtered = \"\".join((filter(lambda x: x == \" \" or x.isalnum(), line)))\n",
    "    return [filtered.split()]\n",
    "\n",
    "def task10(playRDD):\n",
    "    return playRDD.flatMap(task10_flatmap)\n",
    "a = task10(playRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca4157a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACT', 'I']\n",
      "['SCENE', 'I', 'Before', 'LEONATOS', 'house']\n",
      "['Enter', 'LEONATO', 'HERO', 'and', 'BEATRICE', 'with', 'a', 'Messenger']\n"
     ]
    }
   ],
   "source": [
    "for t in a.take(3): print(t)\n",
    "# print(a.takeOrdered(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6944b97e",
   "metadata": {},
   "source": [
    "Task 11 (0.25): This takes as input the playRDD and for each line, finds the first word in the line, and also counts the number of words. It should then filter the RDD by only selecting the lines where the count of words in the line is > 10. The output will be an RDD where the key is the first word in the line, and the value is a 2-tuple, the first being the line and the second being the number of words (which must be >10). Simplest way to do it is probably a map followed by a filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task11_map(line):\n",
    "    filtered = \"\".join((filter(lambda x: x == \" \" or x.isalnum(), line)))\n",
    "    words = filtered.split()\n",
    "    return (words[0], (line, len(words)) )\n",
    "\n",
    "def task11(playRDD):\n",
    "    return playRDD.map(task11_map).filter(lambda x: x[1][1] > 10)\n",
    "a = task11(playRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d1fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in a.take(200): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb39b3",
   "metadata": {},
   "source": [
    "Task 12 (0.25): Write a sequence of transformations starting from prizeRDD that returns an PairRDD where the key is the category (physics etc), and the value is a list of all Nobel Laureates for that category (just their surnames). Make sure the final values are lists, and not some other class objects (if you do a take(5), it should print out the lists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b489125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task12_map(dic):\n",
    "    surnames = []\n",
    "    cat = dic[\"category\"]\n",
    "    laureates = dic[\"laureates\"]\n",
    "    for laur in laureates:\n",
    "        surnames.append(laur[\"surname\"]) # some people dont have surnames\n",
    "    return(cat, surnames)\n",
    "\n",
    "def task12(nobelRDD):\n",
    "    return nobelRDD.map(task12_map).reduceByKey( # set union to remove duplicates\n",
    "                lambda v1, v2: v1 + v2)\n",
    "a = task12(nobelRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7ec861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task12(nobelRDD):\n",
    "    def task12_map(dic):\n",
    "        surnames = set()\n",
    "        cat = dic[\"category\"]\n",
    "        laureates = dic[\"laureates\"]\n",
    "        for laur in laureates:\n",
    "            if laur[\"surname\"] != \"\":\n",
    "                surnames.add(laur[\"surname\"]) # some people dont have surnames\n",
    "        return(cat, surnames)\n",
    "    return nobelRDD.map(task12_map).reduceByKey(\n",
    "                lambda v1, v2: v1 | v2).map(lambda x: (x[0], list(x[1])))\n",
    "a = task12(nobelRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b905b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in a.take(5): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15c856c",
   "metadata": {},
   "source": [
    "Task 13 (0.25): This function operates on the logsRDD. It takes as input a list of dates and returns an RDD with \"hosts\" that were present in the log on all of those dates. The dates would be provided as strings, in the same format that they appear in the logs (e.g., '01/Jul/1995' and '02/Jul/1995'). The format of the log entries should be self-explanatory, but here are more details if you need: NASA Logs Try to minimize the number of RDDs you end up creating. Note that the list of dates may contain more than 2 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3789673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task13_mapper(line):\n",
    "    words = line.split()\n",
    "    host = words[0]\n",
    "    date = words[3][1:12]\n",
    "    return (host, date)\n",
    "\n",
    "\n",
    "def task13(logsRDD, l):\n",
    "    return logsRDD.map(task13_mapper).filter(lambda x: x[1] in l)\n",
    "l = [\"01/Jul/1995\", \"02/Jul/1995\"]\n",
    "a = task13(logsRDD, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb551e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in a.take(200): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a90ed4d",
   "metadata": {},
   "source": [
    "Task 14 (0.25): On the logsRDD, for two given days (provided as input analogous to Task 9 above), use a 'cogroup' to create the following RDD: the key of the RDD will be a host, and the value will be a 2-tuple, where the first element is a list of all URLs fetched from that host on the first day, and the second element is the list of all URLs fetched from that host on the second day. Use filter to first create two RDDs from the input logsRDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b17ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task14(logsRDD, day1, day2):\n",
    "    return dummyrdd\n",
    "a = task14(logsRDD, day1, day2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b6b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in a.take(200): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab3ad56",
   "metadata": {},
   "source": [
    "Task 15 (0.25): Complete a function to calculate the degree distribution of user nodes in the Amazon graph (i.e., amazonBipartiteRDD). In other words, calculate the degree of each user node (i.e., number of products each user has rated), and then use a reduceByKey (or aggregateByKey) to find the number of nodes with a given degree. The output should be a PairRDD where the key is the degree, and the value is the number of nodes in the graph with that degree."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "01b0da322a7df2b881bf69dce4c75684d5ac75b853286a49a713693279c2c23c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
